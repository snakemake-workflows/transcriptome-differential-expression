samples: samples.csv


## General Workflow Parameters:

# Name of the Workflow:
workflow: "workflow-transcriptome-de_phe"

# this is the input directory. All samples are looked for in this directory
inputdir: "/lustre/project/nhr-zdvhpc/transcriptome_data"
# Repository URL:
repo: "https://github.com/snakemake-workflows/transriptome-differential-expression"

## Workflow-specific Parameters:

# the reference genome respectively transcriptome, is defined here:
# You can either provide local reference data or an NCBI accession number do download from
ref:
    species: "Chironomus riparius"
    # Genome, allowed extensions:  .FA or .FASTA or .FNA
    genome: "/lustre/project/nhr-zdvhpc/transcriptome_data/GCA_917627325.4_PGI_CHIRRI_v4_genomic.fa"
    # Annotation, allowed extensions: .GFF or .GTF
    annotation: "/lustre/project/nhr-zdvhpc/transcriptome_data/GCA_917627325.4_PGI_CHIRRI_v4_genomic.gff"    
    # NCBI accession number of the reference data set
    accession: "GCA_917627325.4"



# Minimum read length, put 0 if you want to proceed with all reads.
min_length: 200

# Maximum number of CPUs in your partition/PC/server
max_cpus: 40

# Minimap2 indexing options
minimap_index_opts: ""

# Minimap2 mapping options
minimap2_opts: ""

# Maximum secondary alignments
maximum_secondary: 100

# Secondary score ratio (-p for minimap2)
secondary_score_ratio: 1.0

# Samtools view opts, "-b" creates BAM from SAM.
samtobam_opts: "-b"

# Samtools sort opts,
bamsort_opts: ""

# Salmon library type
salmon_libtype: "U"


# QC options

# Samtools stats opts
bamstats_opts: ""

# Count filtering options - customize these according to your experimental design:

# Genes expressed in minimum this many samples
min_samps_gene_expr: 3
# Transcripts expressed in minimum this many samples
min_samps_feature_expr: 1
# Minimum gene counts
min_gene_expr: 10
# Minimum transcript counts
min_feature_expr: 3

# This section defines the pyDESeq2 plot and data handling parameters
deseq2:
    # normalization fit type, must be 'parametric' or 'mean'
    fit_type: "mean"
    # the "design factors" are the confounding variables to be adjusted fr
    # during normalization. They must be given in the configuration (samples.csv).
    design_factors: 
        - "condition"
    #
    # the "continous factors" are non-categorial factors to be considered
    #continuous_factors:
    #    - 
    #
    # The (log2) log fold change under the null hypothesis. (default: 0).
    lfc_null: 0.5
    #
    # The alternative hypothesis for computing wald p-values. By default,
    # the normal Wald test assesses deviation of the estimated log fold
    # change from the null hypothesis, as given by lfc_null.
    # One of ["greaterAbs", "lessAbs", "greater", "less"] or None.
    # The alternative hypothesis corresponds to what the user wants to
    # find rather than the null hypothesis. (default: None).
    alt_hypothesis: "greaterAbs"
    #
    # The marker size in points**2 (typographic points are 1/72 in.).
    # Default is rcParams['lines.markersize'] ** 2.# minimum count to
    # be considered for subsequent analysis
    point_width: 20
    #
    # we disrecard loci with count number lower 'mincount'
    mincount: 10
    #
    # Type I error cutoff value:
    alpha: 0.05
    #
    # in addition to the full heatmap, plot the top number of different
    # values, ranked by the top ratio between the two traits
    threshold_plot: 10
    #
    # the heatmap color map
    # see https://seaborn.pydata.org/tutorial/color_palettes.htm for an overview
    colormap: "flare"
    #plot figure type
    figtype: "png"
